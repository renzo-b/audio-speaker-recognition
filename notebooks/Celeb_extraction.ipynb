{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Download voxceleb files from this Drive: https://1drv.ms/u/s!AmYq9m5Um8eJjJwQdIIxEnX4_ELPBA?e=nEcboP \n",
    "2. create a function that takes in a wav file and returns a np.array\n",
    "3. take Sinisa's samples and transform them to array\n",
    "3. modify the create_databases() function to create dataframes (one df has a speaker_id and mfcc_id), the other has (mfcc_id,Â mfcc_chanel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VoxCeleb Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from typing import Union\n",
    "from torch.utils.data import Subset\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from scipy.io.wavfile import read\n",
    "import wave\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(r\"C:\\Users\\William Hazen\\Documents\\UofT\\Term 1 (F)\\MIE 1517\\MIE 1517 Projects\\audio-speaker-recognition\\voxceleb\\mfcc_channel_db_64000_16000_13_voxceleb_4s.pkl\", 'rb') as f:\n",
    "    mfcc_channel_db = pickle.load(f)\n",
    "    \n",
    "with open(r\"C:\\Users\\William Hazen\\Documents\\UofT\\Term 1 (F)\\MIE 1517\\MIE 1517 Projects\\audio-speaker-recognition\\voxceleb\\speaker_mfcc_db_64000_16000_13_voxceleb_4s.pkl\", 'rb') as f:\n",
    "    speaker_mfcc_db = pickle.load(f)\n",
    "speaker_mfcc_db = speaker_mfcc_db.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Celeb Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = r\"C:\\Users\\William Hazen\\Documents\\UofT\\Term 1 (F)\\MIE 1517\\MIE 1517 Projects\\audio-speaker-recognition\\Celeb Data\"\n",
    "f = []\n",
    "for (dirpath, dirnames, filenames) in os.walk(mypath):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folders\n",
      "0   Alison Pill\n",
      "1   Amy Poehler\n",
      "2   Chadwick Boseman\n",
      "3   Cillian Murphy\n",
      "4   David Letterman\n",
      "5   Sinisa\n"
     ]
    }
   ],
   "source": [
    "print(\"Folders\")\n",
    "dir_name_list = []\n",
    "count = 0\n",
    "for i, dirname in enumerate(dirnames):\n",
    "    count += 1\n",
    "    dir_name_list.append(dirname)\n",
    "    print(i, ' ', dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "def get_filepaths(directory):\n",
    "    \"\"\"\n",
    "    This function will generate the file names in a directory \n",
    "    tree by walking the tree either top-down or bottom-up. For each \n",
    "    directory in the tree rooted at directory top (including top itself), \n",
    "    it yields a 3-tuple (dirpath, dirnames, filenames).\n",
    "    \"\"\"\n",
    "    file_paths = []  # List which will store all of the full filepaths.\n",
    "\n",
    "    # Walk the tree.\n",
    "    for root, directories, files in os.walk(directory):\n",
    "        for filename in files:\n",
    "            # Join the two strings in order to form the full filepath.\n",
    "            filepath = os.path.join(root, filename)\n",
    "            file_paths.append(filepath)  # Add it to the list.\n",
    "\n",
    "    return file_paths  # Self-explanatory.\n",
    "\n",
    "# Run the above function and store its results in a variable.   \n",
    "full_file_paths = get_filepaths(r\"C:\\Users\\William Hazen\\Documents\\UofT\\Term 1 (F)\\MIE 1517\\MIE 1517 Projects\\audio-speaker-recognition\\Celeb Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_waveform(waveform, window_size):\n",
    "    \"\"\"\n",
    "    Takes an original waveform and reduce to chunks of smaller intervals using a sliding window\n",
    "    \n",
    "    waveform : nd.array\n",
    "    \n",
    "    window_size : int\n",
    "        window size in seconds\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    splitted_waveform : list[nd.array]\n",
    "        list of waveforms\n",
    "    \n",
    "    \"\"\"\n",
    "    splitted_waveform = []\n",
    "    \n",
    "    for i in range(0, len(waveform), window_size):\n",
    "        split = waveform[i:i+window_size]\n",
    "        if len(split) == window_size:\n",
    "            splitted_waveform.append(split)\n",
    "\n",
    "    return splitted_waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_as_np_list = []\n",
    "sample_rate_list = []\n",
    "name_list = []\n",
    "mfccs_list = []\n",
    "unique_list = []\n",
    "speaker_ID_list = []\n",
    "sample_rate = 16000 # 16kHz\n",
    "window_size = 4 * sample_rate # 1 second has 16000 samples, window_size is 4 seconds\n",
    "number_spectral_coefficients = 13\n",
    "\n",
    "def add_custom_samples_to_voxceleb(speaker_mfcc_db, mfcc_channel_db, \n",
    "                                window_size, sample_rate, number_spectral_coefficients):\n",
    "    idx = 300000# mfcc_channel_db.index[-1] + 1\n",
    "\n",
    "    for filename in full_file_paths:\n",
    "        #print('processing: ', filename)\n",
    "        content = filename[113:-4]\n",
    "        split_name = content.split('\\\\')[1]\n",
    "        unique_list.append(split_name[0:4])\n",
    "        name_list.append(split_name)    \n",
    "        # if split_name[0:4] == \"A_Pi\":\n",
    "        #     speaker_ID = 37\n",
    "        # elif split_name[0:4] == \"A_Po\":\n",
    "        #     speaker_ID = 45 \n",
    "        # elif split_name[0:4] == \"C_Bo\":\n",
    "        #     speaker_ID = 139\n",
    "        # elif split_name[0:4] == \"C_Mu\":\n",
    "        #     speaker_ID = 165\n",
    "        # elif split_name[0:4] == \"D_Le\":\n",
    "        #     speaker_ID = 211\n",
    "        if split_name[0:4] == \"Sini\":\n",
    "            speaker_ID = 8888\n",
    "            speaker_ID_list.append(speaker_ID)   \n",
    "            \n",
    "            waveform, sr = librosa.load(filename, sr=sample_rate)\n",
    "            waveform_arr = waveform.flatten()\n",
    "            splitted_waveform = split_waveform(waveform_arr, window_size) # split waveforms into consistent chunks\n",
    "\n",
    "            for chunk in splitted_waveform: # transform waveforms into MFCC spectrograms\n",
    "                mfccs = librosa.feature.mfcc(y=chunk.flatten(), n_mfcc=13, sr=sample_rate)\n",
    "\n",
    "                speaker_mfcc_db.loc[idx, \"speaker_id\"] = speaker_ID\n",
    "                speaker_mfcc_db.loc[idx, \"mfcc_id\"] = idx\n",
    "\n",
    "                for j in range(number_spectral_coefficients):\n",
    "                    mfcc_channel_db.loc[idx, f\"channel_{j}\"] = 1\n",
    "                    try:\n",
    "                        mfcc_channel_db.at[idx, f\"channel_{j}\"] = mfccs[j, :]\n",
    "                    except ValueError:\n",
    "                        print(mfccs.shape)\n",
    "                        # print(mfccs)\n",
    "                        print(mfccs[j, :].shape)\n",
    "                        print(idx)\n",
    "                        print(j)\n",
    "                        assert False\n",
    "\n",
    "                idx += 1\n",
    "\n",
    "    return speaker_mfcc_db, mfcc_channel_db\n",
    "        # audio_as_np_list.append(y)\n",
    "        # sample_rate_list.append(sr)\n",
    "\n",
    "        # # splitted_waveform = split_waveform(y, sr) # split waveforms into consistent chunks\n",
    "\n",
    "        # # for chunk in splitted_waveform: # transform waveforms into MFCC spectrograms\n",
    "        # #     mfccs = librosa.feature.mfcc(y=chunk, n_mfcc=13, sr=sr)\n",
    "        # mfccs = librosa.feature.mfcc(y=y, n_mfcc=13, sr=sr)\n",
    "        # mfccs_list.append(mfccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "channel_0     [-247.41261, -154.02705, -115.005325, -113.405...\n",
       "channel_1     [-44.41731, -40.377876, 6.0169764, 65.17988, 7...\n",
       "channel_2     [45.21265, 54.16138, 50.241623, -5.9958906, -3...\n",
       "channel_3     [-2.825086, 4.182045, 19.290844, 52.145073, 79...\n",
       "channel_4     [6.422141, 5.1642165, -0.5214758, -22.322853, ...\n",
       "channel_5     [11.644709, 8.438548, -19.104036, -27.33027, -...\n",
       "channel_6     [-15.066701, -8.810129, -15.6354475, -5.974414...\n",
       "channel_7     [10.318856, 16.105614, 18.073685, -1.7375027, ...\n",
       "channel_8     [-2.456327, -5.621569, -11.3551445, -14.574454...\n",
       "channel_9     [-0.54953563, -8.83652, -13.031679, -8.721676,...\n",
       "channel_10    [-8.665388, -13.082109, -6.7757463, -8.349026,...\n",
       "channel_11    [-12.409164, -11.899278, -6.3717594, -4.195281...\n",
       "channel_12    [5.049775, 1.687913, -2.1538005, -8.75869, -7....\n",
       "Name: 98544, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfcc_channel_db.loc[98544]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_mfcc_db, mfcc_channel_db = add_custom_samples_to_voxceleb(speaker_mfcc_db, mfcc_channel_db, \n",
    "                                window_size, sample_rate, number_spectral_coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>mfcc_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300048</th>\n",
       "      <td>8888</td>\n",
       "      <td>300048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300049</th>\n",
       "      <td>8888</td>\n",
       "      <td>300049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300050</th>\n",
       "      <td>8888</td>\n",
       "      <td>300050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300051</th>\n",
       "      <td>8888</td>\n",
       "      <td>300051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300052</th>\n",
       "      <td>8888</td>\n",
       "      <td>300052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>230362 rows Ã 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       speaker_id mfcc_id\n",
       "0               0       0\n",
       "1               0       1\n",
       "2               0       2\n",
       "3               0       3\n",
       "4               0       4\n",
       "...           ...     ...\n",
       "300048       8888  300048\n",
       "300049       8888  300049\n",
       "300050       8888  300050\n",
       "300051       8888  300051\n",
       "300052       8888  300052\n",
       "\n",
       "[230362 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speaker_mfcc_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speaker_mfcc_db[speaker_mfcc_db[\"speaker_id\"]==8888]) # sinisa's sample ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_mfcc_db.to_pickle('speaker_mfcc_voxceleb_with_sinisa.pkl')\n",
    "mfcc_channel_db.to_pickle('mfcc_channel_db_voxceleb_with_sinisa.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(audio_as_np_list), len(sample_rate_list), len(name_list), len(speaker_ID_list), len(mfccs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celeb_df = pd.DataFrame({\n",
    "                        \"Speaker Name\": name_list,\n",
    "                        \"NP Waveforms\": audio_as_np_list,\n",
    "                        \"Sample Rate\": sample_rate_list,\n",
    "                        \"MFCC's\": mfccs_list,\n",
    "                        \"speaker_ID_list\": speaker_ID_list,\n",
    "    \n",
    "}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celeb_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- id10039\tAlison_Pill (39) -> (37)\n",
    "- id10046\tAmy_Poehler (47) -> (45)\n",
    "- id10140\tChadwick_Boseman (141) -> (139)\n",
    "- id10166\tCillian_Murphy\t(167) -> (165)\n",
    "- id10212\tDavid_Letterman (213) -> (211)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sinisa_df = celeb_df[celeb_df[\"speaker_ID_list\"] == 1251]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_sinisa_df = sinisa_df.drop([\"NP Waveforms\", \"Speaker Name\", \"Sample Rate\"], axis=1)\n",
    "e_sinisa_df[\"speaker_id\"] = e_sinisa_df[\"speaker_ID_list\"]\n",
    "e_sinisa_df[\"mfcc\"] = e_sinisa_df[\"MFCC's\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_list = []\n",
    "for i in range(50,57):\n",
    "    list_list.append(e_sinisa_df[\"mfcc\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_list)\n",
    "list_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_sinisa_df = e_sinisa_df.drop([\"MFCC's\", \"speaker_ID_list\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sinina_id = e_sinisa_df.drop([\"mfcc\"], axis=1)[0:7]\n",
    "ext = [98544, 98545, 98546, 98547, 98548, 98549, 98550]\n",
    "\n",
    "sinina_id[\"mfcc_id\"] = [98544, 98545, 98546, 98547, 98548, 98549, 98550]\n",
    "sinina_id = sinina_id.set_index(sinina_id.mfcc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_speaker_vox_channel = pd.DataFrame(speaker_vox_channel).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_mfcc_vox_channel = pd.DataFrame(mfcc_vox_channel).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_val = temp_speaker_vox_channel.index.values.tolist() +  [98544, 98545, 98546, 98547, 98548, 98549, 98550]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_sp_vox_channel = pd.concat([temp_speaker_vox_channel, sinina_id])\n",
    "temp_sp_vox_channel.set_index(temp_sp_vox_channel.mfcc_id)\n",
    "temp_sp_vox_channel[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_mfcc_vox_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sin_mfcc_sp = e_sinisa_df.drop([\"speaker_id\"], axis=1)[0:7]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_list = sin_mfcc_sp[\"mfcc\"].values\n",
    "mf_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_list = sin_mfcc_sp[\"mfcc\"].values\n",
    "\n",
    "c=0\n",
    "c1 = 0\n",
    "channel_list = []\n",
    "c_list = []\n",
    "for count in mf_list:\n",
    "    c_list.append(count)\n",
    "    for channel in count:\n",
    "       \n",
    "       channel_list.append(channel)\n",
    "       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_13_list = []\n",
    "for batch in range(13):\n",
    "    ch_13_list = channel_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(channel_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_list = [\"channel_0\", \"channel_1\", \"channel_2\",\"channel_3\",\"channel_4\",\"channel_5\",\"channel_6\",\"channel_7\",\"channel_8\", \"channel_9\", \"channel_10\", \"channel_11\", \"channel_12\"]\n",
    "ext = [98544, 98545, 98546, 98547, 98548, 98549, 98550]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = pd.DataFrame(columns=ch_list, index=ext)\n",
    "df_temp.loc[98544] = list_list[0].tolist()\n",
    "df_temp.loc[98545] = list_list[1].tolist()\n",
    "df_temp.loc[98546] = list_list[2].tolist()\n",
    "df_temp.loc[98547] = list_list[3].tolist()\n",
    "df_temp.loc[98548] = list_list[4].tolist()\n",
    "df_temp.loc[98549] = list_list[5].tolist()\n",
    "df_temp.loc[98550] = list_list[6].tolist()\n",
    "df_temp.rename_axis('mfcc_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sin_mfcc_sp[\"mfcc_id\"] = [98544, 98545, 98546, 98547, 98548, 98549, 98550]\n",
    "# sin_mfcc_sp = sin_mfcc_sp.set_index(sin_mfcc_sp.mfcc_id)\n",
    "# sin_mfcc_sp.drop([\"mfcc_id\", \"mfcc\"],axis=1)\n",
    "# sin_mfcc_sp[\"channel_0\"] = list_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_mfcc_vox_channel = pd.concat([temp_mfcc_vox_channel, df_temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mfcc_databases(dataset, window_size, sample_rate, speaker_dict, number_spectral_coefficients):\n",
    "    \"\"\"\n",
    "    Creates two databases from an audio dataset e.g. librispeech\n",
    "    \n",
    "    Inputs\n",
    "    -----\n",
    "    \n",
    "    base_dataset : \n",
    "        A pytorch audio dataset like librispeech\n",
    "    \n",
    "    window_size : int\n",
    "        window size to be used to consistently split waveforms\n",
    "\n",
    "    sample_rate : int\n",
    "        sample rate in kHz    \n",
    "    \n",
    "    speaker_dict : dict\n",
    "        dictionary of {'speaker_id':encoded_id} pairs          \n",
    "\n",
    "    number_spectral_coefficients : int\n",
    "        number of spectral coefficients to keep for the MFCC calculation\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    speaker_mfcc_db : pd.DataFrame \n",
    "        df with shape (index_id, speaker_id, mfcc_id)\n",
    "    \n",
    "    mfcc_channel_db : pd.DataFrame\n",
    "        df with shape (mfcc_id, channel_id)\n",
    "    \n",
    "    \"\"\"\n",
    "    try:\n",
    "        speaker_mfcc_db = pd.read_pickle(f'speaker_mfcc_db_{window_size}_{sample_rate}_{number_spectral_coefficients}.pkl')\n",
    "        mfcc_channel_db = pd.read_pickle(f'mfcc_channel_db_{window_size}_{sample_rate}_{number_spectral_coefficients}.pkl')\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        speaker_mfcc_db = pd.DataFrame(columns=[\"speaker_id\", \"mfcc_id\"])\n",
    "        mfcc_channel_db = pd.DataFrame(columns=[\"mfcc_id\"]+[f\"channel_{i}\" for i in range(number_spectral_coefficients)]).set_index('mfcc_id')\n",
    "\n",
    "        idx = 0\n",
    "\n",
    "        print('Creating a database. Hold tight...')\n",
    "        for i in tqdm(range(dataset.__len__())):\n",
    "            (waveform, sample_rate, transcript, speaker_id, chapter_id, utterance_id) = dataset.__getitem__(i)\n",
    "            waveform_arr = waveform.numpy().flatten()\n",
    "            splitted_waveform = split_waveform(waveform_arr, window_size) # split waveforms into consistent chunks\n",
    "\n",
    "            for chunk in splitted_waveform: # transform waveforms into MFCC spectrograms\n",
    "                mfccs = librosa.feature.mfcc(y=chunk.flatten(), n_mfcc=13, sr=sample_rate)\n",
    "\n",
    "                speaker_mfcc_db.loc[idx, \"speaker_id\"] = speaker_dict[speaker_id]\n",
    "                speaker_mfcc_db.loc[idx, \"mfcc_id\"] = idx\n",
    "\n",
    "                for j in range(number_spectral_coefficients):\n",
    "                    mfcc_channel_db.loc[idx, f\"channel_{j}\"] = 1\n",
    "                    mfcc_channel_db.at[idx, f\"channel_{j}\"] = mfccs[j, :]\n",
    "                \n",
    "                idx += 1\n",
    "\n",
    "        # speaker_mfcc_db.to_pickle(f'speaker_mfcc_db_{window_size}_{sample_rate}_{number_spectral_coefficients}.pkl')\n",
    "        # mfcc_channel_db.to_pickle(f'mfcc_channel_db_{window_size}_{sample_rate}_{number_spectral_coefficients}.pkl')\n",
    "\n",
    "    return speaker_mfcc_db, mfcc_channel_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_mfcc_databases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = [x for x in ((temp_mfcc_vox_channel[\"channel_0\"][-6:-5]).values)]\n",
    "for x in first:\n",
    "    print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('E_Pickle.pkl', 'wb') as f:\n",
    "#     pickle.dump(temp_sp_vox_channel, f)\n",
    "\n",
    "# with open('S_Pickle.pkl', 'wb') as f:\n",
    "#     pickle.dump(S, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('speech_recon_venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "921c91bd1f2fde06f82e9fa034c0509101df8200655d44526880d040502a2fef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
